% Stycke om progressive GAN och varför jag tror fade-in inte funkar för binär data
This study set out with the aim of assessing the possiblitities of using deep generative models for data augmentation when training deep neural networks on complex data sets. The results of the study confirm that \acrshort{gans} are associated with a highly unstable training procedure, whereas \acrshort{vaes} are more stable and capable of producing more predictable image reconstructions. The most important finding was that \acrshort{gans} can be improved by simultaneous training of an autoencoder. Unlike previous methods combining \acrshort{gans} and autoencoders \parencite{LarsenSW15autoencodingbeyond, nguyen2016plug, donahue2016adversarial, ulyanovVL17adversarial}, no explicit coupling between the autoencoder and \acrshort{gan} exists. Insted sharing generator parameters and the latent space was shown to be sufficient for generating better data sets than any of the baseline methods.

One unanticipated finding in this project was that the fade in approach of \textcite{karras2017progressive} failed to preserve the learned information between the stages of the progressive \acrshort{gan}. A possible explanation of this is that the generator learns to mute the residual connection and compensate by scaling the original signal during the majority of the fade in period. When the fade-in almost is finished and the signal moves towards only using the new connections, the new parameters remain untrained rendering the whole process useless. The fact that this behavior is not reported in \parencite{karras2017progressive} suggests that it is data-dependent. Since the segmentation maps are binary, fake maps can easily be distinguished if they are scaled which indicate that this phenomenon might be triggered by this property of the data. However further investigations are necessary before this can be stated for certain.

The problem of mode collapse is one of the main research frontiers of \acrshort{gans}. The extremely low fake-fake score for the \acrlong{wgan} suggests this model suffered from severe mode collapse. By inspecting the generated images it is clear that this is the case. This outcome is contrary to the original claim by \textcite{arjovsky2017wasserstein} that these models should be liberated from mode collapse. However to be fair, this claim assumes the discriminator to be trained to optimality between each generator iteration which in practice is infeasible. 

While the \acrshort{wgan} suffered from severe mode collapse, both the \acrshort{vae} and the \acrshort{aegan} seem to have learned to capture most of the variance in the original distribution. For the \acrshort{vae} this result is quite expected as mode collapse generally is not a problem for these models. Furthermore, since it mostly learns low-frequency features of the data, there is less variation left to be learned making the accomplishment less impressive. The \acrshort{aegan} on the other hand is partially a normal \acrshort{gan} and should be very susceptible to mode collapse. The fact that it manages to capture the levels of variation in pose, illuminance, eyelid openness etc. suggests that the simultaneous training of an autoencoder improved the the variation of the generated samples as proposed.


%It is believed that this mode of failure is data dependent. Further research on MNIST is proposed to asses this case.

%Diskutera mode collapse. Förvånansvärt litet problem i både AEGAN och karras (tror jag). Kanske minibatch-std som gör det. Sannolikt att AEGAN-ramverket hjälper också, men kan nog inte påstå det.

% TODO: Diskutera metoder som inte hann testas, svårt att säga att AEGAN är bäst.

The present study was as stated designed to determine the effect of training neural networks on data generated by deep generative models. It is reasonable to believe that generated datasets that are qualitatively similar to the original data in terms of visual quality and variation results in better neural networks when training on the generated data. The results of this study indicate that this is the case. 

It is somewhat surprising how well the numbers of the first row in the first subtable in the tables \ref{tab:quantitative_results} and \ref{tab:quantitative_results_real} correspond to the previously discussed visual quality of the data sets. 
The high Jaccard distance for the \acrshort{wgan} can be explained by the severe mode collapse that the model suffered from, making it very difficult to learn anything usable from this model for the semantic segmentation network. Moreover the loss of high-frequency details in the \acrshort{vae} seem to have had a similar effect, making it more difficult to generalize to the real data given only this data. However in this case the generated data seem to be somewhat usable, giving quite reasonable Jaccard distances. The \acrshort{aegan} produced both a good variance and decent looking images with high-frequency details, even though they contained some artifacts and could without too much effort be distinguished from the real data. This resulted in the best Jaccard distances when training solely on the generated data in both cases.

Considering the data augmentation test in the first subtable of tables \ref{tab:quantitative_results} and \ref{tab:quantitative_results_real} instead of the stand alone case for the generative models, it can be observed that the best stand-alone generative model is not the same as the best generative model for data augmentation. Instead the \acrshort{vae} resulted in the lowest Jaccard distance for both the synthetic data and the real world data sets. It seems possible that these results are due to the artifacts produced by the \acrshort{gan} training. When observing the results from training on real data and testing on synthetic one can see that the only case where the Jaccard distance is lower than the baseline is when tested on the \acrshort{vae} images. An interpretation of this is that the absence of high-frequency details causes this data to be easier than the original data in terms of predicting the pupil positions. This means that introducing these images during the training process of a normal network gives relatively small gradients and does not introduce false patterns that the learning process may adjust to. In other words, the \acrshort{vae} does not cause as much harm to the training as the other models may do. 

On the other hand, using the same argument it is sensible to suspect that the \acrshort{vae} is unlikely to provide the type of data that a network could benefit from during training in settings where the need for data augmentation is higher than in the pupil regression experiments, where the existing data volume is more than sufficient for the purpose. This suspicion is further confirmed by the toy experiments presented in table \ref{tab:toy_experiments}. 

In the iris experiment there is no clear improvement using the \acrshort{vae} over no augmentation at all, even though it is sensible to assume that some level of improvement is obtained by reducing over-fitting in the model. However in the MNIST example, the error rate is clearly much higher for the \acrshort{vae} than all the baselines. It is important to keep in mind that the MNIST error rates are all very low, so the difference is with regard to some small set of difficult examples for which it would be very surprising if the \acrshort{vae} augmentation would help. It is also reasonable that augmenting with the \acrshort{vae} data dilutes the corner cases of the training data causing the model to be more confident in the easy cases but having more problems with the edge cases, explaining why this augmentation causes the performance decrease.

These results are not very encouraging, although quite expected. However both of these toy experiments revealed performance improvements when the data sets were augmented by generated data from the \acrshort{aegan}. Although it is important to note that these improvements might as well be due to random chance, they show that the \acrshort{aegan} did not inhibit the learning process of the classifier as in the pupil regression case. Also, in both cases there are reasons to believe that the \acrshort{aegan} augmentation could improve the results. For the iris data set, simply extending the size of the data set by peturbing the data points slightly sould decrease the risk of over-fitting and therefore improve performance of the models. This could of course easily be performed just by adding a small gaussian noise to the data points due to the low-dimensional structure of the data. An advantage of using deep generative models on the other hand is that the approach scales to more complex data sets. Already when considering the MNIST data set, gaussian peturbations is not going to cover the difficult corner cases. Instead when peturbing the data points with the \acrshort{aegan} the shapes are modified, which enforces the classifier to be less sensitive to those kind of changes. This type of peturbations could very well improve the generalization of the models which would explain why the \acrshort{aegan} managed to get a lower error rate than any of the baselines in this case too.



% TODO Ge wgan lite cred ändå och säg att den hade kunnat få en bättre chans
