% Stycke om progressive GAN och varför jag tror fade-in inte funkar för binär data
This study set out with the aim of assessing the posiblitities of using deep generative models for data augmentation when training deep neural networks on complex data sets. The results of the study confirms that \acrshort{gans} are associated with a highly unstable training procedure, whereas \acrshort{vaes} are more stable and capable of producing more predictable image reconstructions. The most important finding was that \acrshort{gans} can be improved by simultaneous training of an autoencoder. Unlike previous methods combining \acrshort{gans} and autoencoders \parencite{LarsenSW15autoencodingbeyond, nguyen2016plug, donahue2016adversarial, ulyanovVL17adversarial}, no explicit coupling between the autoencoder and \acrshort{gan} exists. Insted sharing generator parameters and the latent space was shown to be sufficient for generating better data sets than any of the baseline methods.

One unanticipated finding in this project was that the fade in approach of \textcite{karras2017progressive} failed to preserve the learned information between the stages of the progressive \acrshort{gan}. A possible explanation of this is that the generator learns to mute the residual connection and compensate by scaling the original signal during the majority of the fade in period. When the fade-in almost is finished and the signal moves towards only using the new connections, the new parameters remains untrained rendering the whole process useless. The fact that this behavior is not reported in \parencite{karras2017progressive} suggests that it is data-dependent. Since the segmentation maps are binary, fake maps can easily be distinguished if they are scaled which indicate that this phenomenon might be triggered by this property of the data. However further investigations are necessary before this can be stated for certain.

The problem of mode collapse is one of the main research frontiers of \acrshort{gans}. The extremely low fake-fake score for the \acrlong{wgan} suggests this model suffered from severe mode collapse. By inspecting the generated images it is clear that this is the case. This outcome is contrary to the original claim by \textcite{arjovsky2017wasserstein} that these models should be liberated from mode collapse. However to be fair, this claim assumes the discriminator to be trained to optimality between each generator iteration which in practice is infeasible. 

Wile the \acrshort{wgan} suffered from severe mode collapse, both the \acrshort{vae} and the \acrshort{aegan} seem to have learned to capture most of the variance in the original distribution. For the \acrshort{vae} this result is quite expected as mode collapse generally is not a problem for these models. Furthermore, since it moslty learns low-frequency features of the data, there is less variation left to be learned making the accomplishment less impressive. The \acrshort{aegan} on the other hand is partially a normal \acrshort{gan} and should be very susceptible to mode collapse. The fact that it manages to capture the levels of variation in pose, illuminance, eyelid openness etc. suggests that the simultaneous training of an autoencoder improved the the variation of the generated samples as proposed.


%It is believed that this mode of failure is data dependent. Further research on MNIST is proposed to asses this case.

%Diskutera mode collapse. Förvånansvärt litet problem i både AEGAN och karras (tror jag). Kanske minibatch-std som gör det. Sannolikt att AEGAN-ramverket hjälper också, men kan nog inte påstå det.


