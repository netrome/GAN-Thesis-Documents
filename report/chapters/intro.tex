%Establish the context and importance of the topic in this text.


Generative models are essential for a wide range of applications within Data Science and Machine Learning. Unlike discriminative models, generative models are capable of reproducing the phenomenon they are modelling, enabling them to be used for synthetic data generation. This has been shown to be successful for low dimensional relational data; as example \textcite{patki2016synthetic} showed that generative models could be used as a drop in replacement for a relational database. However, achieving similar results on large high dimensional datasets has proved to be more challenging.

Until recently, there has been little progress in developing generative models that can scale beyond small low-dimensional datasets. Therefore, the most refined generative models of today are intractable to apply on large high-dimensional datasets. The past few years have seen major advances in deep learing. These advances allowed a new class of scalable generative models to emerge, which is today called deep generative models. Of these models, a significant amount of attention have been directed at \acrfull{gans} which are capable of generating highly realistic samples of complicated data distributions.

\acrlong{gans} were first introduced by \textcite{goodfellow2014generative} in 2014 as a method of generating realistic samples of a data distribution. The state-of-the-art \acrshort{gans} of today are capable of generating diverse sets of high resolution images \cite{karras2017progressive}. Adversarial methods have also helped improve existing datasets for gaze estimation \cite{shrivastava2016learning,sela2017gazegan}. 

A considerable amount of literature has been published on how to train \acrshort{gans}. Most of these studies consider convergence issues related to training \acrshort{gans} and the quality of the generated samples. A search of the literature revealed few studies which attempt to train new networks on the generated samples. The aim of this project is to advance the understanding of these possibilities.

\section{Problem statement}
This thesis intends to determine the extent to which deep generative models can act as a drop-in replacement for existing datasets. The question asked is

\begin{framed}
    \textit{Can deep generative models be applied to generate synthetic datasets that can be used to boost the performance of existing discriminative models?} 
\end{framed}


\section{Scope and objectives}
This study is unable to encompass the entire field of deep generative models as well as all possible data sources. Therefore, this study examines the previously stated question through a case study within semantic segmentation for pupil regression. Special emphasis is put on the task of generating synthetic datasets for this task through \acrlong{gans}.

\section{Societal and ethical considerations}
In the new global economy, extracting knowledge from data has become a central issue for a wide range of industries. Generative models play an important role in this process as these models are the most generic methods for finding hidden structures and relationships in large datasets. As more industries move towards a data driven business model, the scalability and applicability of certain generative models in new problem domains are increasingly interesting. The outcomes of this project are especially relevant to industries that utilize large sets of images for supervised learning as it provides valuable insights regarding an approach for learning hidden structures in this type of data.

Another source of interest from the economic perspective emerges from the fact that manually annotated data is expensive and requires large amounts of human labour. Increasing the effectiveness of the existing data might reduce the need for extending the size of the annotated datasets in some cases. 

In the case of very large databases, both economical and ecological benefits exist. A generative model requires only a small fraction of the storage space that the full dataset needs. Therefore, replacing databases with generative models has the potential of saving vast amounts of resources and thus being a both cheaper and more ecological alternative to huge data stores when applicable. Though the relevance of this can be discussed since usually storage is not the main ecological problem and the extra computations required to run the generative model could weigh over the benefits of it.

This approach also comes with an ethical issue. When the data consists of personal information, data belonging to a specific individual can easily be removed from a conventional dataset. However, there is no obvious way to delete the impact of that data onto a trained generative model. It could be argued that by training the generative model, the data have already been anonymized. However, the extent to which this is true depends on the specific model. There are many aspects to consider regarding personal integrity and generative modelling, and a full discussion is well beyond the scope of this project. Due to this and the novelty of the methods, they might provide a loophole to circumvent several data protection laws. This risk is assumed to be quite low given the current state-of-the-art, allowing this thesis to be published but any further incremental research within the field should be aware of it.

\section{Thesis overview}
Chapter 2 provides an overview of \acrlong{gans} and related methods. The notation used throughout the thesis is established in Section 2.1. In Chapter 3, the methods that have been used to answer the problem statement are presented. The experimental results are presented in Chapter 4 and discussed in Chapter 5. In Chapter 6, the final conclusion is stated and further work is discussed.

%\subsection{Semi-supervised learning}

%\subsection{Data compression}

