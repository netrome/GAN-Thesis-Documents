\section{Generative adversarial networks}
\acrfull{gans} are a family generative models proposed by \textcite{goodfellow2014generative}. The framework for training \acrshort{gans} consists of a data set $S$ with elements in a domain $X$, a latent space $Z$ and two neural networks, a generator $G$ and a discriminator $D$. The generator is a mapping from $Z$ to $X$, $G: Z \rightarrow X$. The discriminator is a binary classifier $D: X \rightarrow [0, 1]$. 

The objective of the discriminator is to classify elements in $X$ as either members or not members of $S$. Members of $S$ are usually referred to as real samples since they are part of the data set, and non-members are referred to as fake samples. The objective of the generator is to fool the discriminator by mapping elements in $Z$ to the subspace of $X$ that is classified as real. 

The generator can bee viewed as representing a probability distribution $p_G$ on $X$ according to $p_G(x) = p_Z(G^{-1}(x))$, assuming a distribution $p_Z$ on $Z$. In practice $G^{-1}$ is intractable to compute, whereby explicit probabilities are seldom acquired through \acrshort{gans}. Moreover, the elements of $S$ can be seen as outcomes of a probability distribution $p_S$ corresponding to the probability of the occurence of a specific data point. Using this formulation the objective of the \acrshort{gan} training can be formulated as a minimax game 
\begin{equation}
    \min_D \max_G J^{D}(G, D)
\end{equation}
where $J^D(G, D)$ is the discriminator cost function from \parencite{goodfellow2016nips},
\begin{equation}
    J^D(G, D) = -\frac{1}{2}\mathbb{E}_{x \sim p_S, z \sim p_Z}\left[\log(D(x)) - \log(1 - D(G(z))) \right].
\end{equation}
%\begin{equation}
%    \mathcal{L}(x_1, x_2) = -\log(D(x)) + \log(D(x_2)), \quad \begin{cases} x \in X \\ z \in Z \end{cases}.
%\end{equation}


\subsection{\acrshort{gan} variations}
\subsubsection{BiGAN}
Can utilize the latent space.
\subsubsection{ACGAN}
Generates nice images. \textcite{odena2016conditional} Distribution is skewed. \textcite{shuac2017acganisbad}.
\subsubsection{WGAN}
\subsubsection{BEGAN}
\subsubsection{DRAGAN}
\subsubsection{Progressive GAN}

\section{Other generative models}

\subsection{Variatonal Autoencoders}

\section{Image-to-image transforms}

\section{Common architectures}

\section{Normalization techniques}

\section{Related work}




