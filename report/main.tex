\documentclass{kththesis}

\usepackage{blindtext} % This is just to get some nonsense text in this template, can be safely removed

\usepackage{csquotes} % Recommended by biblatex
\usepackage{biblatex}
\addbibresource{references.bib} % The file containing our references, in BibTeX format

% Own packages -------------------------------------
\usepackage[parfill]{parskip}
\usepackage{multirow}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{svg}
\graphicspath{ {images/} }
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{siunitx}
\usepackage{soul}
\usepackage[colorinlistoftodos, textsize=tiny]{todonotes}
\usepackage[font=small,labelfont=bf]{caption}  % Make captions smaller
\usepackage{framed}

\sisetup{round-mode=figures,round-precision=3}
\sisetup{detect-weight=true}
\usepackage[acronym]{glossaries}
\usepackage{algorithm,algorithmic}% http://ctan.org/pkg/algorithms
\makeglossaries
\newacronym{gan}{GAN}{Generative Adversarial Network}
\newacronym{gans}{GANs}{Generative Adversarial Networks}
\newacronym{vae}{VAE}{Variational Autoencoder}
\newacronym{vaes}{VAEs}{Variational Autoencoders}
\newacronym{mse}{MSE}{Mean Squared Error}
\newacronym{aevb}{AEVB}{Auto Encoding Variational Bayes}
\newacronym{cnn}{CNN}{Convolutional Neural Network}
\newacronym{cnns}{CNNs}{Convolutional Neural Networks}
\newacronym{is}{IS}{Inception Score}
\newacronym{fid}{FID}{Fréchet Inception Distance}
\newacronym{wgan}{WGAN}{Wasserstein GAN}
\newacronym{aegan}{AEGAN}{Autoencoding GAN}
\newacronym{roi}{ROI}{Region Of Interest}
\newacronym{vaegan}{VAEGAN}{Variational Autoencoder + Generative Adversarial Network}
% --------------------------------------------------
% Own commands ---------

\newcommand{\todocomment}[1]{\todo[color=green!40]{#1}}
\newcommand{\todoproofread}[1]{\todo[color=red!40]{#1}}
\newcommand{\ve}[1]{\mathbf{#1}}
\newcommand{\dataset}{\mathcal{S}}
\newcommand{\latentspace}{\mathcal{Z}}
\newcommand{\dataspace}{\mathcal{X}}
\newcommand{\eqdist}{\stackrel{\text{d}}{=}}
% ----------------------

\title{Augmenting High-Dimensional Data with Deep Generative Models}
\alttitle{Högdimensionell dataaugmentering med djupa generativa modeller}
\author{Mårten Nilsson}
\email{marten3@kth.se}
\supervisor{Josephine Sullivan}
\examiner{Hedvig Kjellström}
\programme{Master in Machine Learning}
\school{School of Computer Science and Communication}
\date{\today}


\begin{document}

% Frontmatter includes the titlepage, abstracts and table-of-contents
\frontmatter

\titlepage

\begin{abstract}
Data augmentation is a technique that can be performed in various ways to improve the training of discriminative models. The recent developments in deep generative models offer new ways of augmenting existing data sets. In this thesis, a framework for augmenting annotated data sets with deep generative models is proposed together with a method for quantitatively evaluating the quality of the generated data sets. Using this framework, two data sets for pupil localization was generated with different generative models, including both well-established models and a novel model proposed for this purpose. The unique model was shown both qualitatively and quantitatively to generate the best data sets. A set of smaller experiments on standard data sets also revealed cases where this generative model could improve the performance of an existing discriminative model. The results indicate that generative models can be used to augment or replace existing data sets when training discriminative models.
  %\blindtext
\end{abstract}


\begin{otherlanguage}{swedish}
  \begin{abstract}
      Dataaugmentering är en teknik som kan utföras på flera sätt för att förbättra träningen av diskriminativa modeller. De senaste framgångarna inom djupa generativa modeller har öppnat upp nya sätt att augmentera existerande dataset. I detta arbete har ett ramverk för augmentering av annoterade dataset med hjälp av djupa generativa modeller föreslagits. Utöver detta så har en metod för kvantitativ evaulering av kvaliteten hos genererade data set tagits fram. Med hjälp av detta ramverk har två dataset för pupillokalisering genererats med olika generativa modeller. Både väletablerade modeller och en ny modell utvecklad för detta syfte har testats. Den unika modellen visades både kvalitativt och kvantitativt att den genererade de bästa dataseten. Ett antal mindre experiment på standardiserade dataset visade exempel på fall där denna generativa modell kunde förbättra prestandan hos en existerande diskriminativ modell. Resultaten indikerar att generativa modeller kan användas för att augmentera eller ersätta existerande dataset vid träning av diskriminativa modeller.
  \end{abstract}
\end{otherlanguage}

%\section*{Acknowledgements}
%I would like to thank Josephine Sullivan and Alexander Davies for supervising me throughout this project. This work would not have been possible without you guidance. I would also like to thank Hedvig Kjellström for the effort of Examinating this project. Moreover...

\tableofcontents


% Mainmatter is where the actual contents of the thesis goes
\mainmatter

% Here's my thesis ---------------------------------------------------------------------------------------

\chapter{Introduction}
%Motivation: Data compresion, can express data sets with smaller space requirements. Improved consistency (better annotations). Semi-supervised learning. Implicit semi-supervised learning.
\input{chapters/intro.tex}


\chapter{Background}
\input{chapters/prestudy.tex}

\chapter{Methods}
\input{chapters/method.tex}
%Modelling annotated data: Normal GANs, image-to-image models.

%Modelling partially annotated data: Triple-GAN.

%Normalization technoques. Talk more about spectral normalization. 

%Implementation details: Highlight spectral normalziation observation (about weight matrix spectral norm in convolutional layer due to the shape). Talk about vectorization and viewing convolutions as a linear layer. 

\chapter{Results}
\input{chapters/results.tex}

\chapter{Discussion}
\input{chapters/discussion.tex}

\chapter{Conclusion}
\input{chapters/conclusion.tex}

% --------------------------------------------------------------------------------------------------------

\printbibliography[heading=bibintoc] % Print the bibliography (and make it appear in the table of contents)

%\appendix
%
%\chapter{Lots of images here}

\end{document}
