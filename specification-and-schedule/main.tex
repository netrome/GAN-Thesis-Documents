\documentclass[a4paper]{article}

%% Language and font encodings
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[parfill]{parskip}

%% Sets page size and margins
\usepackage[a4paper,top=3cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

%% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorinlistoftodos, textsize=tiny]{todonotes}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}

\title{DA222X Specification and Schedule}
\author{MÃ¥rten Nilsson \texttt{marten3@kth.se}}

\begin{document}
\maketitle

\section{Formalities}
\begin{itemize}
\item Preliminary title: \textit{Synthetic Data Generation Using Conditional Generative Adversarial Networks}.
\item Supervisor at CSC: \textit{Josephine Sullivan}.
\item Name of the principal: \textit{Tobii}.
\item Supervisor at the principal's workplace: \textit{Alexander Davies}
\end{itemize}

\section{Background \& objective}
The degree project is being carried out within the field of deep learning and
generative modeling. Generative adversarial networks (GANs) were first introduced by Ian
Goodfellow in 2014 \cite{goodfellow2014generative} as a method of generating realistic samples of a data distribution. The state-of-the-art GANs of today are capable of generating diverse sets of high resolution images \cite{karras2017progressive}. Adversarial methods have also been shown to improve existing data sets for gaze estimation \cite{shrivastava2016learning}. A big interest in researching GANs emerges from the unsupervised nature of the method. By utilizing GANs large unannotated data sets can be leveraged to boost existing models. An example of this is semi-supervised learning as proposed by Goodfellow et al. in the original GAN article \cite{goodfellow2014generative}.

The principal, Tobii, is interested in examining the
possibilities of adversarial methods due to the recent results in gaze estimation by Shrivastava et al. \cite{shrivastava2016learning}. Another source of interest is the possibility to reduce the dependency on large annotated data sets which are expensive to obtain.

The desired outcome of the project is to produce a variant of a GAN capable of
generating data sets with improved annotations in comparison to the original data
set. The term Improved in this context applies
both to the quality and the quantity of the annotations.

\section{Research question \& method}
\subsection{The question}
Can current techniques for training GANs be used to train a network to generate a synthetic data set from
an existing source of data in such a way that models trained on the synthetic
data set perform better than the same models when trained on real data?

\subsection{Specified problem definition}
The assignment entails training a neural network using state-of-the-art
techniques to generate annotated data sets. The main challenge involved in this
project is getting the GAN training to converge, due to the instability of the
constellation. There are several known stability issues associated with training
GANs. Another big challenge is identifying the key aspects to adapt from recent
research in the field. Several recent articles in the field claim to overcome
some of the main issues with GANs by different ad-hoc solutions and improvements.
However due to the difficulties in evaluating these methods and the perculiarities of the results it
is reasonable to remain sceptical towards many of these
methods.

\subsection{Examination method}
The algorithms that will be tested are a progressive method for training GANs
\cite{karras2017progressive} to increase training stability and convergence and
a method for leveraging unannotated data such as triple GANs
\cite{li2017triple}. The algorithms will be tested on synthetic data sets where
the variation of the data is controlled as well as real data sets. The data sets
that will be used are images of eyes with pupil annotations. If there are time
for more experiments, the algorithms will also be tested on a data set of faces
with facial landmark annotations. 

\subsection{Expected scientific results}
The hypothesis is that it is possible to increase the performance deep neural networks by augmenting the data set they are trained on with synthetic data generated by another neural network. 
This is scientifically relevant since positive results would impact the methods used to train common deep learning neural networks. 

The hypothesis will be tested by attempting to generate synthetic data sets through adversarial methods and evaluate how an existing deep neural network performs when trained on the synthetic data set versus when trained on the real data set. 

\section{Evaluation  \& news value}
The objective of the degree project is fulfilled when a proposed variant of a GAN has been shown to pass the performance criterion by being tested on an annotated data set. 
The question is adequately answered if the tests either confirm the hypothesis or reveal a set of problems that make the tested approach infeasible.

The finished work is interesting because it either shows a practical application of GANs on a relevant problem or it reveals difficulties and pitfalls that one might encounter when working with GANs. The targeted audience is mainly researchers within deep learning and generative modeling. However with positive results, the work could appeal to anyone interested in image generation. 

\section{Pre-study}
The pre-study will mainly focus on the recent developments within deep learning
and GANs.
The necessary knowledge on background and state-of-the-art will be obtained by
reading the latest articles, reflecting over their results and
looking up the interesting sources from there.
Preliminarily, important references include the original GAN article
\cite{goodfellow2014generative}, the gaze estimation paper that uses adversarial learning \cite{shrivastava2016learning} and the articles containing the most promising results (of which I'm aware) within the field so far \cite{karras2017progressive, miyato2017spectral}.
Other key papers are found within image-to-image transformations \cite{isola2016image,zhu2017unpaired}, variations on GANs \cite{arjovsky2017wasserstein,berthelot2017began,odena2016conditional} and improvements and comparisons of current techniques \cite{salimans2016improved,gulrajani2017improved,lucic2017gans,xiang2017effects}.

\section{Conditions \& schedule}
The resources expected to be needed to solve the problem are mainly data and
compute resources. The data resources needed
is at least one big annotated data set of images where the annotations can be
translated into heat maps of the same shape as the original images.
Regarding computing requirements, this project needs a
system capable of running code written in any common python deep-learning library/framework as well as a powerful graphics card with enough memory for modern GANs.

The project is limited to investigating conditional generative adversarial neural networks for synthetic data sets. Furthermore the project will focus on a progressive learning model and will not test other types of GANS. The methods tested to leverage unannotated data are limited to methods based on the inverse transform of the generator (e.g. cycle-GAN \cite{zhu2017unpaired}, triple-GAN\cite{li2017triple} etc.). 

\subsection{Collaboration with the principal}
The principal will be involved in the project by supplying the
computing resources and data sets necessary to complete the
project.
The external supervisor, Alexander Davies, has undertaken to support the project by participating in discussions related to the implementation, practical issues that arises, choice of method and the final report.

\subsection{Schedule}
\begin{itemize}
    \item Prestudy finished and submitted: 2018-02-05
    \item Data sets prepared: 2018-02-05
    \item Progressive GAN implemented: 2018-02-07
    \item Low resolution fine tuning of Progressive GAN finished: 2018-02-09
    \item First experiment finished: 2018-02-12 
    \item Extension to partially annotated data sets implemented: 2018-02-14
    \item Second experiment finished: 2018-02-19
    \item Complementary experiments performed and finished: 2018-04-09
    \item Complete draft + self evaluation written and submitted: 2018-04-27
    \item Project presented: 2018-05-28
    \item Final report submitted: 2018-06-04
\end{itemize}

\bibliographystyle{unsrt}
\bibliography{sample}

\end{document}
